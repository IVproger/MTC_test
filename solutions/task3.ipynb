{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Статьи: \n",
    "1. https://qna.habr.com/q/1049696\n",
    "2. https://stackoverflow.com/questions/7853628/how-do-i-find-an-image-contained-within-an-image\n",
    "3. https://stackoverflow.com/questions/61067512/locating-a-picture-inside-a-bigger-picture\n",
    "4. https://docs.opencv.org/3.4/de/da9/tutorial_template_matching.html\n",
    "5. https://www.youtube.com/watch?v=vOJ6r0GVLPo\n",
    "\n",
    "Идеи:\n",
    "1) Back projection techique \n",
    "2) Использовать гистограммы, чтобы подобрать схожести в распределениях и накинуть треш холд для выявляения одной картинки на другой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В рамках данной задачи я столкнулся с сложностью мастаюирования реализованного решения для различных типов и форматов изображения и паттерна для мэтчинга. В зависимости от особенностей изображений (шум, количество схожих обьектов, размерность и тд) необходимо использовать разные способы. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Реализация решения №1 для простого случая\n",
    "В рамках данной задачи, я решил сначала применить все имеющиеся классические (статистические) методы поиска паттернов одного изображения на другом. Чаще всего данные способы хорошо себя показывают, когда на изображении мало схожих между собой обьектов и малая зашумленность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_methods = ['cv2.TM_CCOEFF', 'cv2.TM_CCOEFF_NORMED', 'cv2.TM_CCORR', 'cv2.TM_CCORR_NORMED', 'cv2.TM_SQDIFF', 'cv2.TM_SQDIFF_NORMED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mathch_object(matching_methods, main_pic, template_resized):\n",
    "    h, w = template_resized.shape[:-1]\n",
    "    \n",
    "    for method in matching_methods:\n",
    "        name = method\n",
    "        main_copy = main_pic.copy()\n",
    "        method = eval(method)\n",
    "        result = cv2.matchTemplate(main_copy, template_resized, method)\n",
    "        \n",
    "        # bounding box\n",
    "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "        \n",
    "        if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
    "            top_left = min_loc\n",
    "        else:\n",
    "            top_left = max_loc\n",
    "            \n",
    "        bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "        cv2.rectangle(main_copy, top_left, bottom_right, (0, 255, 0), 10)\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.imshow(main_copy)\n",
    "        plt.title(name)\n",
    "        plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тест кейс 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_pic = cv2.imread('../images/mtc_main_page_simple.png')\n",
    "main_pic = cv2.cvtColor(main_pic, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(main_pic)\n",
    "print(main_pic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = cv2.imread(\"../images/mts_logo_cmyk.png\")\n",
    "template = cv2.cvtColor(template, cv2.COLOR_BGR2RGB)\n",
    "template_resized = cv2.resize(template, (100, 100))\n",
    "plt.imshow(template_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mathch_object(matching_methods, main_pic, template_resized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тест кейс 2 (более сложный кейс с множеством отвлекающих обьектов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Реализация решения №2 для более сложного случая\n",
    "\n",
    "Принцип работы\n",
    "Обнаружение ключевых точек: SIFT обнаруживает ключевые точки на обоих изображениях. Ключевые точки — это особые точки на изображении, которые легко распознать при различных условиях освещения и масштаба.\n",
    "\n",
    "Вычисление дескрипторов: Для каждой ключевой точки вычисляется дескриптор — вектор, описывающий локальные особенности вокруг ключевой точки.\n",
    "\n",
    "Сопоставление дескрипторов: FLANN используется для быстрого и эффективного сопоставления дескрипторов между двумя изображениями.\n",
    "\n",
    "Фильтрация совпадений: Применяется тест Лоу для фильтрации ложных совпадений, оставляя только хорошие совпадения.\n",
    "\n",
    "Замечания: данный способ необходимо модифицировать в зависимости от входных данных (подбирать коэффициеты ближайших соседей и менять способ поиска ключевых точек)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_pic_2 = cv2.imread('../images/mtc_main_page.png')\n",
    "main_pic_2 = cv2.cvtColor(main_pic_2, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(main_pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_2 = cv2.imread(\"../images/mts_logo_cmyk.png\")\n",
    "template_2 = cv2.cvtColor(template_2, cv2.COLOR_BGR2RGB)\n",
    "template_resized_2 = cv2.resize(template_2, (100, 100))\n",
    "plt.imshow(template_resized_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mathch_object(matching_methods, main_pic_2, template_resized_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Загрузка изображений\n",
    "source_image = cv2.imread('../images/mtc_main_page.png')\n",
    "template_image = cv2.imread('../images/mts_logo_cmyk.png')\n",
    "\n",
    "# Конвертация изображений в оттенки серого\n",
    "source_gray = cv2.cvtColor(source_image, cv2.COLOR_BGR2GRAY)\n",
    "template_gray = cv2.cvtColor(template_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Обнаружение объектов на изображении\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# Обнаружение ключевых точек и дескрипторов с помощью SIFT\n",
    "keypoints1, descriptors1 = sift.detectAndCompute(template_gray, None)\n",
    "keypoints2, descriptors2 = sift.detectAndCompute(source_gray, None)\n",
    "\n",
    "# Матчинг дескрипторов с помощью FLANN\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "search_params = dict(checks=50)\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "matches = flann.knnMatch(descriptors1, descriptors2, k=2)\n",
    "\n",
    "# Фильтрация совпадений\n",
    "good_matches = []\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.5 * n.distance:\n",
    "        good_matches.append(m)\n",
    "\n",
    "# Поиск хомографичной матрицы\n",
    "if len(good_matches) > 4:\n",
    "    src_pts = np.float32([keypoints1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "    M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "    h, w = template_gray.shape\n",
    "    pts = np.float32([[0, 0], [0, h], [w, h], [w, 0]]).reshape(-1, 1, 2)\n",
    "    dst = cv2.perspectiveTransform(pts, M)\n",
    "    source_image = cv2.polylines(source_image, [np.int32(dst)], True, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "\n",
    "# Показать результат\n",
    "cv2.imshow('Обнаружено', source_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
