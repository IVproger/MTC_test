{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решение #1\n",
    "Сгенерировать набор из 200-300 текстов с фактом продажи и без него, обучить Берт для классификации 1 (факт продажи есть) и 0 (нет факта продажи)\n",
    "\n",
    "Решение #2\n",
    "Cгенерировать набор слов связанных с продажей через словарь и re определять контекс триггер слова \n",
    "\n",
    "Решение #3\n",
    "Подключить через API LLM for text analysis \n",
    "\n",
    "https://habr.com/ru/articles/780008/ - Подлючение Яндекс GPT\n",
    "https://console.yandex.cloud/folders/b1g193u4pfeiog8mgre2 - платформа для аренды Яндекс GPT\n",
    "\n",
    "Бесплтаный вариант Gemini API\n",
    "\n",
    "Решение #4\n",
    "https://www.quora.com/How-can-I-find-the-context-of-a-conversation-using-Machine-Learning-Deep-Learning-NLP-techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вариант решения №1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['иван', 'продать', 'машина', 'михаил', 'сделка', 'завершить', 'понедельник', 'сара', 'собираться', 'купить', 'новый', 'дом', 'следующий', 'месяц']\n",
      "Тема: 0 \n",
      "Слова: 0.071*\"месяц\" + 0.071*\"сара\" + 0.071*\"новый\" + 0.071*\"михаил\" + 0.071*\"сделка\" + 0.071*\"купить\" + 0.071*\"иван\" + 0.071*\"собираться\" + 0.071*\"машина\" + 0.071*\"продать\"\n",
      "Контекст совпадения 0: {'сделка', 'продать', 'купить'}\n",
      "Тема: 1 \n",
      "Слова: 0.071*\"понедельник\" + 0.071*\"следующий\" + 0.071*\"завершить\" + 0.071*\"дом\" + 0.071*\"продать\" + 0.071*\"машина\" + 0.071*\"собираться\" + 0.071*\"иван\" + 0.071*\"купить\" + 0.071*\"сделка\"\n",
      "Контекст совпадения 1: {'сделка', 'продать', 'купить'}\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.lang.ru.stop_words import STOP_WORDS\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "nlp = spacy.load('ru_core_news_sm')\n",
    "\n",
    "text = \"\"\"\n",
    "Иван продал свою машину Михаилу. Сделка была завершена в понедельник.\n",
    "Сара собирается купить новый дом в следующем месяце.\n",
    "\"\"\"\n",
    "\n",
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_.lower() for token in doc if token.text.lower() not in STOP_WORDS and token.is_alpha]\n",
    "    return tokens\n",
    "\n",
    "tokens = preprocess(text)\n",
    "print(tokens)\n",
    "\n",
    "context_words = [\n",
    "    'себестоимость', 'долгосрочный', 'финансовый', 'скидка', 'потребитель', 'купить', 'аукцион', 'бартер', 'дебет',\n",
    "    'маржа', 'торг', 'рассрочка', 'арендатор', 'рынок', 'биржевой', 'субаренда', 'заказ', 'распродажа', 'счёт',\n",
    "    'капитал', 'актив', 'тендер', 'торговать', 'аренда', 'капитализация', 'вложение', 'сделка', 'рыночный', 'скидочный',\n",
    "    'спрос', 'клиент', 'на', 'интерес', 'доход', 'реализовать', 'инвестиция', 'банковский', 'выручка', 'запрос',\n",
    "    'рентабельность', 'операция', 'сбыт', 'курс', 'торговый', 'и', 'коммерсант', 'расчёт', 'условие', 'наличный',\n",
    "    'продавать', 'краткосрочный', 'биржа', 'стоимость', 'контракт', 'сдавать', 'кредит', 'перевод', 'карта', 'закупка',\n",
    "    'предложение', 'комиссионный', 'ликвидность', 'приобрести', 'арендный', 'убыток', 'соглашение', 'депозит', 'платёж',\n",
    "    'оплата', 'выставить', 'транзакция', 'договор', 'арендовать', 'покупка', 'арендодатель', 'цена', 'реализация',\n",
    "    'торговля', 'оферта', 'залог', 'продавец', 'покупатель', 'продажа', 'плата', 'обмен', 'приобретение', 'бюджет',\n",
    "    'продать', 'товар', 'прокат', 'прибыль', 'пассивы', 'срок', 'лизинг'\n",
    "]\n",
    "\n",
    "dictionary = corpora.Dictionary([tokens])\n",
    "corpus = [dictionary.doc2bow(tokens)]\n",
    "\n",
    "lda_model = LdaModel(corpus, num_topics=2, id2word=dictionary, passes=15)\n",
    "\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(f\"Тема: {idx} \\nСлова: {topic}\")\n",
    "    topic_words = [word.split('*')[1].strip().strip('\"') for word in topic.split('+')]\n",
    "    matching_words = set(topic_words) & set(context_words)\n",
    "    if matching_words:\n",
    "        print(f\"Контекст совпадения {idx}: {matching_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вариант решения №2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вариант решения №3\n",
    "\n",
    "## Преимущества: \n",
    "1) С помощью большой открытой языковой моделью от Gemini AI от Google, можно с легкостью анализировать самый различный диапазон текстов и проводить детальный семантический анализ смысла заложенного в тексты. \n",
    "2) Большой потенциал для promt инжениринга для улучшения качества анализа и работы с текстами. \n",
    "3) Простая реализация и гибкость к заднным условиям задачи.\n",
    "\n",
    "## Недостатки:\n",
    "1) Для работы необходимо иметь включенный VPN с шифрованием локации.\n",
    "2) Тексты отправляются на \"ту\" сторону - не целесообразно с точки зрения безопасности и политики работы с пользовательскими данными.\n",
    "3) Ограничения работы API сервиса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Чтение тест кейсов\n",
    "path_test_cases = '../test_cases_for_task1'\n",
    "\n",
    "documents = []\n",
    "\n",
    "for filename in os.listdir(path_test_cases):\n",
    "    file_path = os.path.join(path_test_cases, filename)\n",
    "    if os.path.isfile(file_path): \n",
    "        with open(file_path, 'r') as file:\n",
    "            content = file.read()\n",
    "            documents.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# Исключительно для демонстрационных целей, я использую прямой импорт зашифрованного API ключа, в продакшине необходимо перенести это в env среду или локальный список параметров\n",
    "MY_API_KEY = 'AIzaSyBYOxSeyastEu5JE4I4b0NiXJ1uu4TlUAM'\n",
    "genai.configure(api_key=MY_API_KEY)\n",
    "\n",
    "# Экпорт интерфеса для взаимодействия с моделью\n",
    "model = genai.GenerativeModel('models/gemini-1.5-flash')\n",
    "\n",
    "# В зависимости от того, что для нас является фактом продажи мы можем модифицировать промт и выделить важные детали\n",
    "promt = '''\n",
    "\"In the provided text, you need to determine whether there is a fact of buying or selling something, \n",
    "the conclusion of a transaction, etc. Clearly distinguish when the text directly states this context, \n",
    "and when only the potential or possibility is discussed — this should be considered as the absence of a transaction. \n",
    "If you have found such a context, explain why, and if not, answer 'no.' Provide the answer in Russian.\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('ru_core_news_sm')\n",
    "\n",
    "# Предобработка текст\n",
    "for i, text in enumerate(documents):\n",
    "    \n",
    "    # приведение к нижнему регистру\n",
    "    tmp = nlp(text.lower()) \n",
    "    \n",
    "    filtered_words = []\n",
    "    \n",
    "    # Удаление стоп слов и леммизация \n",
    "    for word in tmp:\n",
    "        if not word.is_stop and not word.is_punct:  \n",
    "            filtered_words.append(word.lemma_)\n",
    "    \n",
    "    predprocesssed_text = \" \".join(filtered_words)\n",
    "    \n",
    "    # TODO установить максимальный размер batch текста подаваемый в модель\n",
    "    \n",
    "    # Отправка предобработанного текста модели\n",
    "    response = model.generate_content(f'''\n",
    "    Analyze the following text:\n",
    "\n",
    "    {predprocesssed_text}\n",
    "                                  \n",
    "    {promt}   \n",
    "    ''')\n",
    "    \n",
    "    # Получение результата \n",
    "    print(f\"Результат анализа текста №{i} {response.text}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
